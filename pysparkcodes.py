from pyspark.sql.types import *
from pyspark.sql.types import DateType, StructType, StructField
from kafka import KafkaProducer
from kafka import KafkaConsumer
'''
KISchema=StructType([StructField('ReferNumber',StringType(),True)
,StructField('FinancialDate',StringType(),True)
,StructField('LocalTime',StringType(),True)
,StructField('LocalDate',StringType(),True)
,StructField('InTime',StringType(),True)
,StructField('OutTime',StringType(),True)
,StructField('TraceNo',StringType(),True)
,StructField('Amount',LongType(),True)
,StructField('AcquireCurrency',StringType(),True)
,StructField('CardNo',StringType(),True)
,StructField('AcquireBankCode',StringType(),True)
,StructField('IssuerBankCode',StringType(),True)
,StructField('LocalOrShetab',StringType(),True)
,StructField('FromAccountNo',StringType(),True)
,StructField('ToAccountNo',StringType(),True)
,StructField('ProcessCode',StringType(),True)
,StructField('Branch',StringType(),True)
,StructField('Merchantnumber',StringType(),True)
,StructField('OnlineOROffline',StringType(),True)
,StructField('TerminalTypeCode',StringType(),True)
,StructField('TerminalNo',StringType(),True)
,StructField('ResponseCode',StringType(),True)
,StructField('ReturnCode',StringType(),True)
,StructField('MessageType',StringType(),True)
,StructField('StatusCode',StringType(),True)
,StructField('SuccessOrFailure',StringType(),True)
,StructField('ReferenceNo',StringType(),True)
,StructField('TransactionAmount',LongType(),True)
,StructField('IssuerCurrency',StringType(),True)
,StructField('SettlementDateInIssuerSwitch',StringType(),True)
,StructField('RevisoryAmount',LongType(),True)
,StructField('ExpireDate',StringType(),True)
,StructField('SourceOrganization',StringType(),True)
,StructField('TraceNoforTransactionswithREVERSAL',StringType(),True)
,StructField('DateforTransactionwithREVERSAL',StringType(),True)
,StructField('TimeforTransactionwithREVERSAL',StringType(),True)
,StructField('AcquireforTransactionwithREVERSAL',StringType(),True)
,StructField('IssuerforTransactionwithREVERSAL',StringType(),True)
,StructField('Shetabfee',LongType(),True)
,StructField('Networkfee',LongType(),True)
,StructField('Acquirefee',LongType(),True)
,StructField('AccountIssuerBranch',StringType(),True)
,StructField('InDate',StringType(),True)
,StructField('PrivateUse',StringType(),True)
,StructField('BillNumber',StringType(),True)
,StructField('PaymentNumber',StringType(),True)
,StructField('BillTypeandOrganizationCode',StringType(),True)
,StructField('OperationNo',StringType(),True)
,StructField('Wage',StringType(),True)
,StructField('UnKnown',StringType(),True)])
'''
pqDF = spark.read.parquet("hdfs://10.100.136.40:9000/user/hduser/pqData")
pqDF.createOrReplaceTempView("pqView")

import pyspark.sql.functions as func

merchantDF = pqDF.groupBy("Merchantnumber").agg(func.sum("Amount"))
pdf = merchantDF.toPandas()
pdf.to_json()

#sqldf = spark.sql("SELECT Amount, FinancialDate FROM baView WHERE FinancialDate between '94\/12\/01' and '94\/12\/29' LIMIT 100")
            #sqldf = spark.sql("SELECT Amount, CardNo FROM baView")
            #sqldf = spark.sql("SELECT Amount, FinancialDate FROM baView WHERE FinancialDate='94\/12\/01' EXCEPT SELECT Amount, 'fake' FROM baView WHERE FinancialDate='94\/12\/01'")
            #FinancialDate between '94\/08\/01' and '94\/11\/30' and
            #WHERE ProcessCode='000000' and MessageType='200' and SuccessOrFailure='s'
#sqldf = spark.sql("SELECT Merchantnumber, Amount  FROM pqView WHERE FinancialDate between '94\/08\/01' and '94\/11\/30' and ProcessCode='000000' and MessageType='200' and SuccessofFailure LIKE '%S%' GROUP BY Merchantnumber")
            #dataframe = sqldf.toPandas()
            #dataframe.to_json()
